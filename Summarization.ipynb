{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1nqxBiKidXqcvymOeAvXcKHY_Jb_FQSUs",
      "authorship_tag": "ABX9TyMSmdGS1Wc1Up90AmMEgID8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gebeyaw/30-Days-Of-HTML/blob/master/Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab output wrapper"
      ],
      "metadata": {
        "id": "KzopH4bQHup-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Transformers"
      ],
      "metadata": {
        "id": "ec-5s9mcH9wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install transformers with sentencepiece\n",
        "!pip install transformers\n",
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwy6oxdwH-ha",
        "outputId": "58c9f1f9-3a44-4f2a-89b5-cb13169856c7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read input file from Google Drive"
      ],
      "metadata": {
        "id": "JSQyprCQIIaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# open and read the file from google drive\n",
        "file = open(\"/content/drive/MyDrive/ES2002c.transcript.txt\", \"r\")\n",
        "FileContent = file.read().strip()\n",
        "     "
      ],
      "metadata": {
        "id": "SGpw62kWIJRO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display file content\n",
        "FileContent = [\"\"\"All things in the universe seem to be constructed out of little parts coming together for greater possibility and greater choices. We call this “maximizing for optionality.”\n",
        "\n",
        "That means the collective ability to do something more, and greater: to become more than the sum of their parts. Sub-quanta come together into atoms; atoms come together into stars and then planets, as they condense.\n",
        "\n",
        "From chemicals to organisms\n",
        "\n",
        "Protocells begin to emerge from chemical processes, and gradually RNA and DNA begin to emerge. From this, we see the first single-celled organisms.  And they form biofilms to protect themselves, which they coordinate through radio-like signaling mechanisms.\n",
        "\n",
        "What we’re seeing here is an exchange between multiple single-celled organisms. The ones on the outside are at greater risk of attack and damage. But these organisms also commensurately have a greater option for finding more food or more resources. \n",
        "\n",
        "Quid pro quo\n",
        "\n",
        "Actually, there’s something called “metabolic codependence,” where inner and outer organisms yo-yo. The outer ones expand, but then they run out of an enzyme they need, so the inner ones then govern how fast the biofilm can expand. \n",
        "\n",
        "Inner organisms want to ensure an equitable trade of resources to feed them, so they provide the enzyme necessary to the outer ones, keeping them strong.\n",
        "\n",
        "There is a quid pro quo, a trade between these different elements in the greater organism.\n",
        "\n",
        "Along came mitochondria, and with them, eukaryotic cells, enabling cells to be warm-blooded, powered from within. This seems to be a fortuitous “accident” — mitochondria were once their own lifeform, which found greater negentropy by pairing up with a cell for their mutual benefit. \n",
        "\n",
        "Symbiotic plants\n",
        "\n",
        "Then came organisms able to harness an even greater throughput of energy by coming together as clumps of what would later become plants and fungi. Plants can take in energy from the sun via chlorophyll, and fungi can break down matter that otherwise resists decay.\n",
        "\n",
        "However, the plants had another coordination problem: bigger plants that grew very tall would sometimes block out the sun for the younger ones. So trees coordinate to leave some room in the canopy for light to reach the bottom, a phenomenon known as “tree crown shyness.” They also subsidize the growth of younger plants, sending them nutrients in symbiosis with fungi.\n",
        "\n",
        "The “wood wide web”\n",
        "\n",
        "Meanwhile, mycelium webs beneath the forest floor enable plants to swap messages and resources even between species, warning of attacks and exchanging resources for mutual strength.\n",
        "\n",
        "This messaging is, essentially, based on the same fundamental principle as civilization — technologies to make a dangerous world more reliably safe, achieved through coordination of effort and resources. This “wood wide web” enables ecosystems to prosper mutually, again demonstrating the tendency of systems to maximize negentropy.\n",
        "\n",
        "The birth of brains\n",
        "\n",
        "Nature has found many answers to these coordination problems, which seem reasonably equitable. Maybe we could learn from that: some of these cells (possibly mycelium-style cells) began to exhibit extra agency. \n",
        "\n",
        "They began to connect to other cells that also specialize in this behavior. They became stronger over time, and eventually turned into brains and cortices. That’s why we see harmonics and action potentials akin to swarms of bees within the brain. \n",
        "\n",
        "Emergence of “free will”\n",
        "\n",
        "These cells still preserved some of their agency — albeit now a collective agency within the greater mass. And out of this, our sense of “free will” likely manifests. \n",
        "\n",
        "We perceive ourselves as one individual. But in truth, we are a nation of ~86 billion tiny souls pulling us in all directions, our ego functioning as both ambassador and president, trying to keep a lid on it all. \n",
        "\n",
        "Come together, right now…\n",
        "\n",
        "In many ways, this is also a little bit like cellular automata — a macroscale version of microscale neurons. This ability to come together enables ants, for example, to carry off the tasty treat. But it also enables formidable feats of coordination. \n",
        "\n",
        "Here we have a bolus of ants. Some are drowning, but swap with ones that aren’t drowning. By working together, they can survive. As with a biofilm, the ants most exposed get a little bit of extra help, or sometimes swap around with fresher ants. \n",
        "\n",
        "We next saw the emergence of cold-blooded creatures, such as reptiles. They were long-lived and hardy but hampered by an inability to operate at all temperatures. They had to bask for a long time to gather enough energy to go into the world. \n",
        "\n",
        "More complex, responsive brains\n",
        "\n",
        "The advent of endothermy, warm-blooded creatures, enabled sustained activity to support a more complex and responsive brain at the expense of greater nutritional intake.\n",
        "\n",
        "The mammalian brain also supports emotions far more sophisticated than the simple Fight, Flight, Feed, and Fornicate impulses of the reptilian brain. Mammals bond with each other in ways that reptiles cannot. Mammals are driven to protect their offspring and friends, encouraging coordination for hunting and watchkeeping. \n",
        "\n",
        "This ability for mammals to bond with each other enabled our ancestors to bond with dogs and later cats. By hunting, we gain more resources for our big brains. This bonding allowed us to divide our labor so efficiently that some were now able to devote themselves exclusively to thinking. \n",
        "\n",
        "They created new inventions, narratives, and ways of conceptualizing the world — new ways of solving problems and bringing people together in shared meaning.\n",
        "\n",
        "Linking up\n",
        "\n",
        "That sense of meaning and the trust gained by common rules of engagement (morals) enabled us to have tolerance for lots of strangers, and thus tribes became nations. Today, we have planetary information and energy networks linking all of us together.\n",
        "\n",
        "\n",
        "Along with being able to split the load of work with other humans and other species, we harnessed the secret of fire, developing an obligate dependence upon it. \n",
        "\n",
        "Fire enabled us to process inedible foods into something safe and nutritious. As our ability to work together in massively distributed, highly specialized labor chains improved, we were able to harness further forms of fire — coal, steam, uranium, to keep us warm. Now, our entire city colonies are heat islands.\n",
        "\n",
        "So are there innate laws of ethics?\n",
        "\n",
        "It may be possible for a system trained on a lot of information to pinpoint this seeming truth: the “will” of the universe is trying to connect things for their mutual negative entropy (slowing down the gradual decline into disorder), allowing for mutual improved optionality.\n",
        "\n",
        "So if different organisms, from plants to ants to human beings, have come together to solve these problems, does it follow that there are innate constructive laws of ethics?\n",
        "\n",
        "What if an AI could prove definitively that there are such constructive laws for ethics, pinpointing an ethical maxim of “good”? A self-evident, evolutionary epiphany that one can’t unsee once realizing it. \n",
        "\n",
        "Something like: \n",
        "\n",
        "(a) Maximizing optionality, which means minimizing entropy, or maximizing negative entropy, through collective benefit that is … \n",
        "\n",
        "(b) by invitation — not by coercion, not by co-opting, but through equitable mutual benefit. We may even define love in the same way. M. Scott Peck defined love as “The will to extend oneself for the purpose of nurturing our own or another’s spiritual growth.” That sounds pretty aligned to me.\n",
        "\n",
        "In the immortal words of Eden Abbez, “the greatest thing you’ll ever learn is just to love and be loved in return.”\n",
        "\n",
        "Perhaps that loving sentiment is more applicable than we knew, expressing “the will of the universe” at all scales and across all time.\"\"\"\n",
        "]"
      ],
      "metadata": {
        "id": "0qVettaEK8n_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total characters in the file\n",
        "len(FileContent[0]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NYTR0R9LB1R",
        "outputId": "8184a5e6-cb95-49e7-9a77-ada37917b8b1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7685"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Model and Tokenizer"
      ],
      "metadata": {
        "id": "8VWJp84sLFQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import and initialize the tokenizer and model from the checkpoint\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "checkpoint = \"sshleifer/distilbart-cnn-12-6\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "52GRttCWLF9z"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some model statistics"
      ],
      "metadata": {
        "id": "6tl1SP2nLJqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# max tokens including the special tokens\n",
        "tokenizer.model_max_length \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ9wVn0ALKTx",
        "outputId": "e927a314-8252-4992-8fe1-9a849f99b10f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# max tokens excluding the special tokens\n",
        "tokenizer.max_len_single_sentence \n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbdvCk0ILORN",
        "outputId": "1bbfc183-2c3f-4b06-ba31-b6adee1ad0f9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1022"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of special tokens\n",
        "tokenizer.num_special_tokens_to_add() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlVYdolRLOUh",
        "outputId": "b260875f-aa14-46ab-fe5a-2175f2a32f27"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert file content to sentences"
      ],
      "metadata": {
        "id": "2dichMadLU-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the sentences from the document\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "sentences = nltk.tokenize.sent_tokenize(FileContent[0])\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoA-_x1ULXp0",
        "outputId": "aa0502be-e24d-4d13-fcd3-2eb7257a5c81"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find the max tokens in the longest sentence\n",
        "max([len(tokenizer.tokenize(sentence)) for sentence in sentences])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP-3M2vILbDl",
        "outputId": "9fde75d2-379e-4b75-c726-4e965f957007"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the chunks"
      ],
      "metadata": {
        "id": "Say6lXxGLdNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize\n",
        "length = 0\n",
        "chunk = \"\"\n",
        "chunks = []\n",
        "count = -1\n",
        "for sentence in sentences:\n",
        "  count += 1\n",
        "  combined_length = len(tokenizer.tokenize(sentence)) + length # add the no. of sentence tokens to the length counter\n",
        "\n",
        "  if combined_length  <= tokenizer.max_len_single_sentence: # if it doesn't exceed\n",
        "    chunk += sentence + \" \" # add the sentence to the chunk\n",
        "    length = combined_length # update the length counter\n",
        "\n",
        "    # if it is the last sentence\n",
        "    if count == len(sentences) - 1:\n",
        "      chunks.append(chunk.strip()) # save the chunk\n",
        "    \n",
        "  else: \n",
        "    chunks.append(chunk.strip()) # save the chunk\n",
        "    \n",
        "    # reset \n",
        "    length = 0 \n",
        "    chunk = \"\"\n",
        "\n",
        "    # take care of the overflow sentence\n",
        "    chunk += sentence + \" \"\n",
        "    length = len(tokenizer.tokenize(sentence))\n",
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTcDiFTXLhAk",
        "outputId": "ba1a3e0c-bf25-4ff8-f449-2b6b756314c7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some checks"
      ],
      "metadata": {
        "id": "DNXi7QXaLkae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[len(tokenizer.tokenize(c)) for c in chunks]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj31BiUKLmnS",
        "outputId": "305c5cdf-34e6-4993-de11-65773a6cf0cf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1014, 984, 960, 1003, 1020, 988, 996, 998, 1017, 576]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[len(tokenizer(c).input_ids) for c in chunks]\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiVMOSJqLqBt",
        "outputId": "4fe2c0ec-4cba-4ce6-a3f3-850599129bf0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1016, 986, 962, 1005, 1022, 990, 998, 1000, 1019, 578]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With special tokens added"
      ],
      "metadata": {
        "id": "yxbgsBTKLsfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum([len(tokenizer(c).input_ids) for c in chunks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAm_F4ilLute",
        "outputId": "1fca5823-5dc8-4313-9a22-54e1be9f889f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9576"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer(FileContent).input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQA9txNNLx1o",
        "outputId": "0c1dcf0b-ab22-44f8-e80f-beb5466fe71f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (9561 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9561"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without special tokens added"
      ],
      "metadata": {
        "id": "GCQV6NN3L0Qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum([len(tokenizer.tokenize(c)) for c in chunks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFlRiQGcL2PF",
        "outputId": "44ab8285-7822-4ba4-a8dd-acbb665263e1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9556"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.tokenize(FileContent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di94ezgyL5qq",
        "outputId": "b5dbf693-9f16-4ddc-b5b4-baac7098d2b3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9559"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the inputs"
      ],
      "metadata": {
        "id": "GHiYEx-zL7Vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs to the model\n",
        "inputs = [tokenizer(chunk, return_tensors=\"pt\") for chunk in chunks]"
      ],
      "metadata": {
        "id": "hhj2oL54L9Lh"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output"
      ],
      "metadata": {
        "id": "xTZrrU0OL_Iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input in inputs:\n",
        "  output = model.generate(**input)\n",
        "  print(tokenizer.decode(*output, skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o-4PwOqMBwS",
        "outputId": "bf8c3acc-4d72-4594-a0e8-438321e70cc0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (142) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " All things in the universe seem to be constructed out of little parts coming together for greater possibility and greater choices. We call this “maximizing for optionality” that means the collective ability to do something more, and greater: to become more than the sum of their parts. This ability to come together enables ants, for example, to carry off the tasty treat, and enables formidable feats of coordination.\n",
            " The 'will' of the universe is trying to connect things for their mutual negative entropy allowing for mutual improved optionality. So if different organisms, from plants to ants to human beings, have come together to solve these problems, does it follow that there are innate constructive laws of ethics? What if an AI could prove definitively that such constructive laws for ethics?\n"
          ]
        }
      ]
    }
  ]
}